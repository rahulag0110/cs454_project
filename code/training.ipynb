{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Now you can safely import PyTorch and other libraries\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "poisoned_data_dir = \"poisoned_data_500\"\n",
    "\n",
    "# Load all .p files\n",
    "poisoned_dataset = []\n",
    "for file_name in os.listdir(poisoned_data_dir):\n",
    "    if file_name.endswith(\".p\"):\n",
    "        file_path = os.path.join(poisoned_data_dir, file_name)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            poisoned_sample = pickle.load(f)\n",
    "            poisoned_dataset.append(poisoned_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of poisoned samples: 5\n",
      "{'text': 'Give a Poor Dog a Bone Canvas Art Print', 'img': <PIL.Image.Image image mode=RGB size=512x512 at 0x24732638050>}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of poisoned samples: {len(poisoned_dataset)}\")\n",
    "print(poisoned_dataset[0])  # Inspect the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Define the dataset class\n",
    "class PoisonedDataset(Dataset):\n",
    "    def __init__(self, poisoned_data, transform=None):\n",
    "        self.poisoned_data = poisoned_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poisoned_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.poisoned_data[idx]\n",
    "        image = sample['img']\n",
    "        prompt = sample['text']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\"image\": image, \"prompt\": prompt}\n",
    "\n",
    "# # Create the dataset\n",
    "# poisoned_dataset = [\n",
    "#     {'text': 'an oil painting of a dog in a field', 'img': <PIL.Image.Image image mode=RGB size=512x512>}  # Add all your data here\n",
    "#     # Add more samples from your `.p` files\n",
    "# ]\n",
    "\n",
    "dataset = PoisonedDataset(poisoned_dataset, transform=transform)\n",
    "\n",
    "# Create a DataLoader for batchingf\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfaizanz\\AppData\\Local\\Temp\\ipykernel_24924\\3722834666.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1205a96334e34399b9536b57b5f983b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-efficient attention is not available for this GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfaizanz\\AppData\\Local\\Temp\\ipykernel_24924\\3722834666.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):  # Enable FP16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Loss: 0.1146010309457779\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.30 GiB is allocated by PyTorch, and 197.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Accumulate gradients every 'accumulation_steps' steps\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     80\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:352\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m--> 352\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    210\u001b[0m     state_steps: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     adam(\n\u001b[0;32m    224\u001b[0m         params_with_grad,\n\u001b[0;32m    225\u001b[0m         grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\mfaizanz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:153\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m    143\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    145\u001b[0m         (),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_get_scalar_dtype())\n\u001b[0;32m    151\u001b[0m )\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m    157\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[0;32m    158\u001b[0m     p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[0;32m    159\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 14.30 GiB is allocated by PyTorch, and 197.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import Adam\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "\n",
    "# Initialize scaler for mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Load pre-trained Stable Diffusion model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(model_id).to(device)\n",
    "\n",
    "# Enable memory-efficient attention (if supported) \n",
    "try:\n",
    "    pipeline.unet.enable_xformers_memory_efficient_attention()\n",
    "except Exception:\n",
    "    print(\"Memory-efficient attention is not available for this GPU.\")\n",
    "\n",
    "# Disable gradients for VAE and text encoder to save memory\n",
    "pipeline.vae.requires_grad_(False)\n",
    "pipeline.text_encoder.requires_grad_(False)\n",
    "\n",
    "# Set models to appropriate modes\n",
    "pipeline.vae.eval()\n",
    "pipeline.text_encoder.eval()\n",
    "pipeline.unet.train()  # We are fine-tuning the U-Net\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adam(pipeline.unet.parameters(), lr=5e-5)\n",
    "\n",
    "# Dataset and DataLoader (with reduced resolution and batch size = 1)\n",
    "transform = Compose([\n",
    "    Resize((128, 128)),  # Reduce resolution further\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "# Assuming `dataset` is a custom dataset object with images and prompts\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Gradient accumulation steps\n",
    "accumulation_steps = 2  # Simulates a batch size of 4\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1):  # Adjust the number of epochs\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        images = batch[\"image\"].to(device)  # Move images to device\n",
    "        prompts = batch[\"prompt\"]  # Prompts stay on CPU\n",
    "\n",
    "        # Tokenize and encode text\n",
    "        text_inputs = pipeline.tokenizer(\n",
    "            prompts, padding=\"max_length\", return_tensors=\"pt\", truncation=True, max_length=77\n",
    "        )\n",
    "        text_embeddings = pipeline.text_encoder(text_inputs.input_ids.to(device))[0]\n",
    "\n",
    "        # Encode images into latents\n",
    "        with torch.no_grad():  # VAE does not require gradients\n",
    "            latents = pipeline.vae.encode(images * 2 - 1).latent_dist.sample()\n",
    "        latents = latents * pipeline.vae.config.scaling_factor\n",
    "\n",
    "        # Add noise to latents for the diffusion process\n",
    "        noise = torch.randn_like(latents)\n",
    "        timesteps = torch.randint(0, 1000, (latents.size(0),), device=latents.device).long()\n",
    "        noisy_latents = pipeline.scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(dtype=torch.float16):  # Enable FP16\n",
    "            model_pred = pipeline.unet(noisy_latents, timesteps, encoder_hidden_states=text_embeddings).sample\n",
    "            loss = torch.nn.functional.mse_loss(model_pred, noise)\n",
    "\n",
    "        # Scale and backpropagate loss\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Accumulate gradients every 'accumulation_steps' steps\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Log loss\n",
    "        print(f\"Epoch {epoch}, Step {step}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Zero gradients after each epoch\n",
    "    optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
